#!/bin/bash

program="flresub"
ncores="$1"
flmlarg="$2"
jobname="$3"

execution_time="00:20"
sparse_flag=""
omp_threads=2
project_group="z19-cse"
queue_name="short"


# Always set this so bc does floating point
export BC_ENV_ARGS="-l"


if [ "$jobname" == "" ]
then
    echo "usage: $program <ncores> <flml prefix> <job name> "
    echo "	    [ -t #_openmp_threads (def.=$omp_threads) ]"
    echo "	    [ -s ]"
    echo "	    [ -x execution_time (format=HH:MM) (def.=$execution_time) ]"
    echo "	    [ -p project_group (def.=$project_group) ]"
    echo "	    [ -q queue_name (def.=standard. | short, long, low) ]"
    echo ""
    echo " *** NOTE: -h and/or -m must be specified"
    exit 1
fi



OPTIND=4
while getopts "t:s:p:x:q:" option
do
    case "${option}"
        in
        	x) execution_time=${OPTARG};;
                s) sparse_flag="sparse";;
                t) omp_threads=${OPTARG};;
                p) project_group=${OPTARG};;
                q) queue_name=${OPTARG};;
    esac
done




true_omp_threads="$omp_threads"
if [ "$sparse_flag" == "sparse" ]
then
    node_width=12
    socket_width=6
else
    node_width=24
    socket_width=12
fi



# Hardware limits


# calculated 
mpi_per_socket=`echo "$socket_width/$omp_threads" | bc | sed 's/\..*$//g'`
mpi_per_node=`echo "$node_width/$omp_threads" | bc | sed 's/\..*$//g'`
total_cores=`echo "$ncores * $omp_threads" | bc | sed 's/\..*$//g'`

nremainder=`echo "$total_cores/$node_width" | bc | sed 's/.*\(\..*$\)/0\1/g'`

testzero=`echo "$nremainder==0" | bc`

if [ "$testzero" == "0" ]
then
    nnodes=`echo "($total_cores + $node_width)/$node_width" | bc | sed 's/\..*$//g'`
else
    nnodes=`echo "$total_cores/$node_width" | bc | sed 's/\..*$//g'`
fi

if [ "$sparse_flag" == "sparse" ]
then
    charged_cores=`echo "$nnodes * $node_width * 2" | bc | sed 's/\..*$//g'`
else
    charged_cores=`echo "$nnodes * $node_width" | bc | sed 's/\..*$//g'`
fi


flprefix="$flmlarg"
flfiles=`\ls -f "$flprefix"_*.flml 2> /dev/null`


if [ "$flfiles" == "" ]
then
    flfiles=`\ls -f "$flprefix".flml 2> /dev/null`
    if [ "$flfiles" == "" ]
    then
	echo "*** error: $program cannot find FLML files matching '""$flmlarg""_*.flml'"
	exit 1
    fi
fi


last_file=""
last_simtime=-1
last_finishtime=-1

for flmlfile in $flfiles
do
    simtime=`cat $flmlfile | grep -A1 "<current_time>" | tail -n 1 - | sed 's/.*<real_value.*>\(.*\)<\/real_value>.*/\1/g'`

    finishtime=`cat $flmlfile | grep -A1 "<finish_time>" | tail -n 1 - | sed 's/.*<real_value.*>\(.*\)<\/real_value>.*/\1/g'`
    
    if [ "$simtime" != "" ] && [ "$finishtime" != "" ]
    then
	if [ `echo "$simtime > $last_simtime" | bc` == 1 ]
	then
	    last_file="$flmlfile"
	    last_simtime=$simtime
	    last_finishtime=$finishtime
	fi
    fi
done



if [ `echo "$last_simtime >= $last_finishtime" | bc ` == 1 ] \
    || [ "$last_simtime" == "-1" ]
then
    echo "**** END OF SIMULATION"
    echo " current_time: $last_simtime"
    echo " finish_time : $last_finishtime"
    echo " flml_file   : $last_file" 
    echo ""
    echo "Exiting flresub"

    exit 0
fi



echo "**** RESTARTING SIMULATION"
echo "Still not reached finish_time ($last_finishtime)."
echo "Using $last_file"
echo "current_time = $last_simtime"



datfile=$flprefix.detectors.dat
ndats=`seq 0 100`

if test -f $datfile
then
    echo "*** Backing up $datfile"

    for num in $ndats
    do
        if ! test -f $datfile.$num
        then
            echo "Moving to $datfile.$num"
            mv -f $datfile $datfile.$num
            break
        fi
    done
fi




qsubfile=/tmp/.qsub.$USER.$$
# jobname="lill_t=$last_simtime"

fluidityExec=$COASTED_HOME/bin/fluidity

if [ "$FLUIDITY_INTEL" == "yes" ]
then
    fluidityModule="fluidity-intel"
else
#    fluidityModule="fluidity-gcc"
    fluidityModule="coasted-gcc"
fi



echo "#!/bin/bash --login
#PBS -N $jobname
#PBS -l select=$nnodes
#PBS -l walltime=$execution_time:00
#PBS -A $project_group

 module use /work/z01/z01/gpsgibb/coasted/modules

module unload PrgEnv-cray
module unload PrgEnv-intel
module load $fluidityModule

# export PATH=$PATH:$COASTED_HOME/bin:/work/y07/y07/cse/vtk/5.10.1/GNU/bin
# export PYTHONPATH=$PYTHONPATH:$FLUIDITY_HOME/python
 export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/home/y07/y07/cse/anaconda/2.2.0-python2/lib/:/work/y07/y07/cse/vtk/5.10.1/GNU/lib/vtk-5.10/


export OMP_NUM_THREADS=$true_omp_threads

# Change to the directory that the job was submitted from
export PBS_O_WORKDIR=\$(readlink -f \$PBS_O_WORKDIR)
cd \$PBS_O_WORKDIR

# The following take a copy of the Fluidity Python directory and 
# put it in the current directory. If we don't do this, we get import errors. 
export WORKING_DIR=\$(pwd -P)


#rm -rf .python

#mkdir .python
#mkdir .python/fluidity
#mkdir .python/windtools
#mkdir .python/tidetools
#mkdir .python/numpy

#cp -rf \$COASTED_HOME/python/* .python/fluidity
#cp -f /work/d67/d67/shared/fluiditylibraries/python/windtools/*.py .python/windtools
#cp -f /work/d67/d67/shared/fluiditylibraries/python/tidetools/*.py .python/tidetools


# copy turbine previous state to backup
#cp -f turbines.state turbines.state.bak


export PYTHONPATH=\$WORKING_DIR/.python/fluidity:\$WORKING_DIR/.python/windtools:\$WORKING_DIR/.python/tidetools:\$PYTHONPATH
echo $PYTHONPATH

# Set the number of MPI tasks
export NPROC=\`qstat -f \$PBS_JOBID | awk '/mppwidth/ {print \$3}'\`
# Set the number of MPI tasks per node
export NTASK=\`qstat -f \$PBS_JOBID | awk '/mppnppn/  {print \$3}'\`

aprun -n $ncores -N $mpi_per_node -S $mpi_per_socket -d $omp_threads $fluidityExec -l -v1  $last_file

## clean up the python directory
# rm -rf .python

" > $qsubfile

# Make a copy for debugging

cp $qsubfile qsub.$$

echo ""
echo "--=----=----=----=----=----=----=----=----=----=----=----=----=----=----=----=--"
echo "qsub: submitting job $jobname -"
echo "   cores: $total_cores"
echo " charged: $charged_cores"
echo ""
echo " runtime: $run_hours""h"
echo "aprun -n $ncores -N $mpi_per_node -S $mpi_per_socket -d $omp_threads $fluidityExec -l -v1  $last_file"

if [ "$sparse_flag" == "sparse" ]
then
    echo "*** sparsely populated"
fi
echo ""

rm -f $jobname.{e,o}*

qsub -q $queue_name -N $jobname $qsubfile


echo "--=----=----=----=----=----=----=----=----=----=----=----=----=----=----=----=--"

# If anything goes amiss, halt submissions
if [ $? -eq 1 ]
then
    echo "**** error: qsub -N $jobname $qsubfile failed. Aborting."
    exit 1
fi

# rm -f $qsubfile
